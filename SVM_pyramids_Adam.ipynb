{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as cPickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score,confusion_matrix,multilabel_confusion_matrix,recall_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import svm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_filenames = cPickle.load(open('resources/train_images_filenames.dat','rb'))\n",
    "test_images_filenames = cPickle.load(open('resources/test_images_filenames.dat','rb'))\n",
    "train_labels = cPickle.load(open('resources/train_labels.dat','rb'))\n",
    "test_labels = cPickle.load(open('resources/test_labels.dat','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIFTdetector = cv2.SIFT_create(nfeatures=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dense_sift(gray,sift,step):\n",
    "    step_size = step\n",
    "    kp = [cv2.KeyPoint(x, y, step_size) for y in range(0, gray.shape[0], step_size) \n",
    "                                        for x in range(0, gray.shape[1], step_size)]\n",
    "    dense_feat = sift.compute(gray, kp)\n",
    "    dense_feat_des = dense_feat[1]\n",
    "    return dense_feat_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:38:24 started doing step=5\n"
     ]
    }
   ],
   "source": [
    "step=5\n",
    "\n",
    "today = datetime.now()\n",
    "dt_string = today.strftime(\"%H:%M:%S\")\n",
    "print(f\"{dt_string} started doing step={step}\")\n",
    "\n",
    "Train_descriptors = []\n",
    "Train_label_per_descriptor = []\n",
    "\n",
    "for filename,labels in zip(train_images_filenames,train_labels):\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "#     kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "    des=compute_dense_sift(gray,SIFTdetector, step)\n",
    "    Train_descriptors.append(des)\n",
    "    Train_label_per_descriptor.append(labels)\n",
    "\n",
    "D=np.vstack(Train_descriptors)\n",
    "\n",
    "k=128\n",
    "codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "codebook.fit(D)\n",
    "\n",
    "visual_words=np.zeros((len(Train_descriptors),k),dtype=np.float32)\n",
    "for i in range(len(Train_descriptors)):\n",
    "    words=codebook.predict(Train_descriptors[i])\n",
    "    visual_words[i,:]=normalize(np.bincount(words,minlength=k).reshape(1,-1))\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=37,n_jobs=-1,metric='manhattan')\n",
    "# knn.fit(visual_words, train_labels) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2704"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Train_descriptors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Train_descriptors[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,   0.,   5., 156.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,  19.],\n",
       "       [  0.,   0.,   0., ...,   1.,   0.,   0.],\n",
       "       ...,\n",
       "       [121.,  55.,  71., ...,   0.,   0.,   0.],\n",
       "       [127.,  68.,  56., ...,   0.,   0.,   0.],\n",
       "       [ 65.,  26.,  23., ...,   0.,   0.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_descriptors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   2.,\n",
       "         0.,   0.,   0.,   0.,   2.,   2.,   4.,  26.,   4.,   0.,   0.,\n",
       "         0.,  26.,   5.,   3.,   5.,   0.,   0.,   0.,   8.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  57.,  31.,   1.,\n",
       "         0.,   0.,   0.,  96.,  82., 156., 156.,   8.,   0.,   0.,  17.,\n",
       "       156.,  41.,  24.,  19.,   0.,   0.,   0., 125.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  25.,  29.,   0.,   0.,\n",
       "        23.,   7., 156., 116., 124.,  76.,   0.,   0., 105., 156., 156.,\n",
       "        57.,   4.,   0.,   0.,   0.,   5., 156.], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_descriptors[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5086224, 128)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 128 artists>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "ax.bar(range(0,len(visual_words[0])),visual_words[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.2904518e-01,  2.8340241e-01, -5.2440875e-05, ...,\n",
       "         2.7040341e+00,  1.5243635e+00, -5.0918347e-01],\n",
       "       [-5.0084454e-01, -4.2245156e-01, -9.4701856e-01, ...,\n",
       "         3.7807378e-01,  1.0506330e+00,  1.0141057e+00],\n",
       "       [-3.7261423e-01,  1.7570947e+00, -2.5433454e-01, ...,\n",
       "        -3.5719883e-01,  1.8915541e+00,  2.7169831e+00],\n",
       "       ...,\n",
       "       [-4.6841028e-01, -9.1849536e-01, -6.9462395e-01, ...,\n",
       "        -8.8673288e-01, -1.1178370e+00, -5.5334848e-01],\n",
       "       [-5.2947927e-01, -9.1849536e-01, -1.0414289e+00, ...,\n",
       "        -9.8765981e-01, -1.1178370e+00, -9.3841881e-01],\n",
       "       [ 2.8545897e+00, -3.2634673e-01, -6.3784790e-01, ...,\n",
       "        -6.0094148e-01, -2.5497204e-01,  4.2291367e-01]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(visual_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Kernel with scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adama\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\adama\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\adama\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\adama\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.79012345679013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adama\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "lin_clf = svm.LinearSVC(max_iter=2000)\n",
    "lin_clf.fit(visual_words, train_labels)\n",
    "\n",
    "visual_words_test=np.zeros((len(test_images_filenames),k),dtype=np.float32)\n",
    "for i in range(len(test_images_filenames)):\n",
    "    filename=test_images_filenames[i]\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "#     kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "    des=compute_dense_sift(gray,SIFTdetector, step)\n",
    "    words=codebook.predict(des)\n",
    "    visual_words_test[i,:]=normalize(np.bincount(words,minlength=k).reshape(1,-1))\n",
    "\n",
    "visual_words_test=scaler.transform(visual_words_test)\n",
    "scores = cross_val_score(lin_clf, visual_words_test, test_labels, cv=5)\n",
    "accuracy=scores.mean()*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF Kernel with scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.92255195153746\n"
     ]
    }
   ],
   "source": [
    "rbf_svc = svm.SVC(kernel='rbf')\n",
    "rbf_svc.fit(visual_words, train_labels)\n",
    "\n",
    "visual_words_test=np.zeros((len(test_images_filenames),k),dtype=np.float32)\n",
    "for i in range(len(test_images_filenames)):\n",
    "    filename=test_images_filenames[i]\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "#     kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "    des=compute_dense_sift(gray,SIFTdetector, step)\n",
    "    words=codebook.predict(des)\n",
    "    visual_words_test[i,:]=normalize(np.bincount(words,minlength=k).reshape(1,-1))\n",
    "\n",
    "visual_words_test=scaler.transform(visual_words_test)\n",
    "scores = cross_val_score(rbf_svc, visual_words_test, test_labels, cv=5)\n",
    "\n",
    "accuracy=scores.mean()*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor filename,labels in zip(train_images_filenames,train_labels):\\n    ima=cv2.imread(filename)\\n    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\\n    break\\n\\ntiles = get_pyramid_image_cells(gray,2)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pyramid_image_cells(image,level):\n",
    "    # CURRENTLY WORKING ONLY FOR LEVELS 0,1,2 (1,4, and 16 cells)\n",
    "    M = (image.shape[0])//(level+1)\n",
    "    N = (image.shape[1])//(level+1)\n",
    "    tiles = [image[x:x+M,y:y+N] for x in range(0,image.shape[0],M) for y in range(0,image.shape[1],N)]\n",
    "    #print(image.shape)\n",
    "    #print(\"level=\", level)\n",
    "    #print(\"returning \" + str(len(tiles)) + \" tiles\")\n",
    "    return tiles\n",
    "\n",
    "\n",
    "'''\n",
    "for filename,labels in zip(train_images_filenames,train_labels):\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    break\n",
    "\n",
    "tiles = get_pyramid_image_cells(gray,2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating a histogram per cell and concatenating them\n",
    "Compute a histogram for each part of the image and put these histograms together in a weighted concatenation \n",
    "(since there will be less words overall in a smaller cell).\n",
    "The weighted concatenation can be a simple normalization of every histogram so the area of the histogram adds up to 1.\n",
    "A pyramid of l levels will yield in 2^(2l) histograms n_words = k*(1+2**(2*pyramid_levels)).\n",
    "the final image histogram is a concatenated vector  of  the  bin  values  of  all  the  histograms in  the  pyramid.\n",
    "concatenation method used in:\n",
    "http://lear.imag.fr/pub/203-bosch-civr07.pdf\n",
    "https://core.ac.uk/download/pdf/82695491.pdf\n",
    "\n",
    "TODO: Initialisation of concatenated_histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:43:06 started doing step=5\n"
     ]
    }
   ],
   "source": [
    "step=5\n",
    "\n",
    "today = datetime.now()\n",
    "dt_string = today.strftime(\"%H:%M:%S\")\n",
    "print(f\"{dt_string} started doing step={step}\")\n",
    "\n",
    "Train_descriptors = []\n",
    "Train_label_per_descriptor = []\n",
    "pyramid_levels = 1 # level zero has 1 tile, level 1 has 4 tiles => 5 histograms that will be concatenated\n",
    "for filename,labels in zip(train_images_filenames,train_labels):\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    # break the image into pieces\n",
    "    image_cells = []\n",
    "    for i in range(pyramid_levels+1):\n",
    "\n",
    "        level_cells = get_pyramid_image_cells(gray,level=i)\n",
    "        image_cells = image_cells + level_cells\n",
    "        # compute descriptors for each tile\n",
    "    Train_descriptors_cell = []\n",
    "    for cell in image_cells:\n",
    "        des=compute_dense_sift(cell,SIFTdetector, step)\n",
    "        Train_descriptors_cell.append(des)\n",
    "        \n",
    "    Train_descriptors.append(Train_descriptors_cell)\n",
    "    Train_label_per_descriptor.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1881"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Train_label_per_descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Train_descriptors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2704"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Train_descriptors[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Train_descriptors[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   2.,\n",
       "         0.,   0.,   0.,   0.,   2.,   2.,   4.,  26.,   4.,   0.,   0.,\n",
       "         0.,  26.,   5.,   3.,   5.,   0.,   0.,   0.,   8.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  57.,  31.,   1.,\n",
       "         0.,   0.,   0.,  96.,  82., 156., 156.,   8.,   0.,   0.,  17.,\n",
       "       156.,  41.,  24.,  19.,   0.,   0.,   0., 125.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  25.,  29.,   0.,   0.,\n",
       "        23.,   7., 156., 116., 124.,  76.,   0.,   0., 105., 156., 156.,\n",
       "        57.,   4.,   0.,   0.,   0.,   5., 156.], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_descriptors[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train all cells as separate images\n",
    "D=np.vstack([des for descriptors_cells in Train_descriptors for des in descriptors_cells])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10172448, 128)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(batch_size=2560, compute_labels=False, n_clusters=128,\n",
       "                random_state=42, reassignment_ratio=0.0001, verbose=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=128\n",
    "codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "codebook.fit(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n"
     ]
    }
   ],
   "source": [
    "print(k*(1+2**(2*pyramid_levels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2704"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Train_descriptors[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words=np.zeros((len(Train_descriptors),k*(1+2**(2*pyramid_levels))),dtype=np.float32)\n",
    "for idx,cells in enumerate(Train_descriptors):\n",
    "\n",
    "    image_histograms = []\n",
    "    for id2,image_cell in enumerate(cells):\n",
    "        cell_words = codebook.predict(image_cell)\n",
    "        image_histograms.append(normalize(np.bincount(cell_words,minlength=k).reshape(1,-1)))\n",
    "        # concatenated histogram has k*(1+2**(2*pyramid_levels)) bins\n",
    "        # normalize(np.bincount(words,minlength=k).reshape(1,-1))\n",
    "\n",
    "    concatenated_histogram=image_histograms[0].copy()\n",
    "    for cell_idx in range(1,len(image_histograms)):\n",
    "        # concatenate histograms\n",
    "        concatenated_histogram = np.concatenate((concatenated_histogram,image_histograms[cell_idx]))\n",
    "    visual_words[idx,:]=concatenated_histogram.flatten()\n",
    "    \n",
    "    #visual_words[idx,:]=np.bincount(words,minlength=k*(2**(2*pyramid_levels))) # this will just be longer as levels \n",
    "                                                                                # increase \n",
    "                                                                                # see: k*(2**(2*pyramid_levels)) long\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=37,n_jobs=-1,metric='manhattan')\n",
    "# knn.fit(visual_words, train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(640,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_words[0,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINED Visual Words tryin further worked until now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40763286,  0.691217  , -0.45509702, ..., -0.23473613,\n",
       "        -0.67555463, -0.5401656 ],\n",
       "       [ 2.5998132 , -0.16144308, -0.55367327, ..., -0.69723225,\n",
       "        -0.67555463, -0.5401656 ],\n",
       "       [-0.787279  ,  0.536344  , -0.3041571 , ..., -0.56693673,\n",
       "        -0.4232162 , -0.2186262 ],\n",
       "       ...,\n",
       "       [-0.8521179 , -1.1338605 , -0.24922338, ..., -0.69723225,\n",
       "        -0.67555463,  1.6228691 ],\n",
       "       [-0.19370893, -1.2179574 , -0.5328649 , ..., -0.69723225,\n",
       "        -0.67555463,  1.5077168 ],\n",
       "       [ 0.6190558 ,  0.62688756,  2.9522593 , ...,  0.09981892,\n",
       "         0.559341  , -0.5401656 ]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(visual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(max_iter=2000)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_clf = svm.LinearSVC(max_iter=2000)\n",
    "lin_clf.fit(visual_words, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:05:42 started doing step=5\n"
     ]
    }
   ],
   "source": [
    "today = datetime.now()\n",
    "dt_string = today.strftime(\"%H:%M:%S\")\n",
    "print(f\"{dt_string} started doing step={step}\")\n",
    "\n",
    "Test_descriptors = []\n",
    "Test_label_per_descriptor = []\n",
    "pyramid_levels = 1 # level zero has 1 tile, level 1 has 4 tiles => 5 histograms that will be concatenated\n",
    "for filename,labels in zip(test_images_filenames,test_labels):\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    # break the image into pieces\n",
    "    image_cells = []\n",
    "    for i in range(pyramid_levels+1):\n",
    "\n",
    "        level_cells = get_pyramid_image_cells(gray,level=i)\n",
    "        image_cells = image_cells + level_cells\n",
    "        # compute descriptors for each tile\n",
    "    Test_descriptors_cell = []\n",
    "    for cell in image_cells:\n",
    "        des=compute_dense_sift(cell,SIFTdetector, step)\n",
    "        Test_descriptors_cell.append(des)\n",
    "        \n",
    "    Test_descriptors.append(Test_descriptors_cell)\n",
    "    Test_label_per_descriptor.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words_test=np.zeros((len(Test_descriptors),k*(1+2**(2*pyramid_levels))),dtype=np.float32)\n",
    "for idx,cells in enumerate(Test_descriptors):\n",
    "\n",
    "    image_histograms = []\n",
    "    for id2,image_cell in enumerate(cells):\n",
    "        cell_words = codebook.predict(image_cell)\n",
    "        image_histograms.append(normalize(np.bincount(cell_words,minlength=k).reshape(1,-1)))\n",
    "        # concatenated histogram has k*(1+2**(2*pyramid_levels)) bins\n",
    "        # normalize(np.bincount(words,minlength=k).reshape(1,-1))\n",
    "\n",
    "    concatenated_histogram=image_histograms[0].copy()\n",
    "    for cell_idx in range(1,len(image_histograms)):\n",
    "        # concatenate histograms\n",
    "        concatenated_histogram = np.concatenate((concatenated_histogram,image_histograms[cell_idx]))\n",
    "    visual_words_test[idx,:]=concatenated_histogram.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.73130894870025\n"
     ]
    }
   ],
   "source": [
    "visual_words_test=scaler.transform(visual_words_test)\n",
    "scores = cross_val_score(lin_clf, visual_words_test, test_labels, cv=5)\n",
    "accuracy=scores.mean()*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
