{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as cPickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score,confusion_matrix,multilabel_confusion_matrix,recall_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import svm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_filenames = cPickle.load(open('resources/train_images_filenames.dat','rb'))\n",
    "test_images_filenames = cPickle.load(open('resources/test_images_filenames.dat','rb'))\n",
    "train_labels = cPickle.load(open('resources/train_labels.dat','rb'))\n",
    "test_labels = cPickle.load(open('resources/test_labels.dat','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIFTdetector = cv2.SIFT_create(nfeatures=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dense_sift(gray,sift,step):\n",
    "    step_size = step\n",
    "    kp = [cv2.KeyPoint(x, y, step_size) for y in range(0, gray.shape[0], step_size) \n",
    "                                        for x in range(0, gray.shape[1], step_size)]\n",
    "    dense_feat = sift.compute(gray, kp)\n",
    "    dense_feat_des = dense_feat[1]\n",
    "    return dense_feat_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:35:52 started doing step=5\n"
     ]
    }
   ],
   "source": [
    "step=5\n",
    "\n",
    "today = datetime.now()\n",
    "dt_string = today.strftime(\"%H:%M:%S\")\n",
    "print(f\"{dt_string} started doing step={step}\")\n",
    "\n",
    "Train_descriptors = []\n",
    "Train_label_per_descriptor = []\n",
    "\n",
    "for filename,labels in zip(train_images_filenames,train_labels):\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "#     kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "    des=compute_dense_sift(gray,SIFTdetector, step)\n",
    "    Train_descriptors.append(des)\n",
    "    Train_label_per_descriptor.append(labels)\n",
    "\n",
    "D=np.vstack(Train_descriptors)\n",
    "\n",
    "k=128\n",
    "codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "codebook.fit(D)\n",
    "\n",
    "visual_words=np.zeros((len(Train_descriptors),k),dtype=np.float32)\n",
    "for i in range(len(Train_descriptors)):\n",
    "    words=codebook.predict(Train_descriptors[i])\n",
    "    visual_words[i,:]=normalize(np.bincount(words,minlength=k))\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=37,n_jobs=-1,metric='manhattan')\n",
    "# knn.fit(visual_words, train_labels) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  3.,  3., ...,  3.,  4.,  3.],\n",
       "       [ 0.,  0.,  6., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  2.,  1., ...,  3.,  0.,  4.],\n",
       "       ...,\n",
       "       [ 1.,  0.,  5., ...,  0.,  1.,  1.],\n",
       "       [ 2.,  0.,  3., ...,  1.,  3.,  2.],\n",
       "       [ 0.,  0.,  6., ...,  1.,  1., 12.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "visual_words=scaler.fit_transform(visual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adama\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\adama\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\adama\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\adama\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.67203435319378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adama\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "lin_clf = svm.LinearSVC(max_iter=2000)\n",
    "lin_clf.fit(visual_words, train_labels)\n",
    "\n",
    "# rbf_svc = svm.SVC(kernel='rbf')\n",
    "# rbf_svc.fit(visual_words, train_labels)\n",
    "\n",
    "visual_words_test=np.zeros((len(test_images_filenames),k),dtype=np.float32)\n",
    "for i in range(len(test_images_filenames)):\n",
    "    filename=test_images_filenames[i]\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "#     kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "    des=compute_dense_sift(gray,SIFTdetector, step)\n",
    "    words=codebook.predict(des)\n",
    "    visual_words_test[i,:]=normalize(np.bincount(words,minlength=k))\n",
    "\n",
    "visual_words_test=scaler.transform(visual_words_test)\n",
    "scores = cross_val_score(lin_clf, visual_words_test, test_labels, cv=5)\n",
    "# scores = cross_val_score(rbf_svc, visual_words_test, test_labels, cv=5)\n",
    "accuracy=scores.mean()*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.19108964036499\n"
     ]
    }
   ],
   "source": [
    "# lin_clf = svm.LinearSVC(max_iter=2000)\n",
    "# lin_clf.fit(visual_words, train_labels)\n",
    "\n",
    "rbf_svc = svm.SVC(kernel='rbf')\n",
    "rbf_svc.fit(visual_words, train_labels)\n",
    "\n",
    "visual_words_test=np.zeros((len(test_images_filenames),k),dtype=np.float32)\n",
    "for i in range(len(test_images_filenames)):\n",
    "    filename=test_images_filenames[i]\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "#     kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "    des=compute_dense_sift(gray,SIFTdetector, step)\n",
    "    words=codebook.predict(des)\n",
    "    visual_words_test[i,:]=normalize(np.bincount(words,minlength=k))\n",
    "\n",
    "visual_words_test=scaler.transform(visual_words_test)\n",
    "# scores = cross_val_score(lin_clf, visual_words_test, test_labels, cv=5)\n",
    "scores = cross_val_score(rbf_svc, visual_words_test, test_labels, cv=5)\n",
    "accuracy=scores.mean()*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
