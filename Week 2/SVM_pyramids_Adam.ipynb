{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as cPickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score,confusion_matrix,multilabel_confusion_matrix,recall_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import svm\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_filenames = cPickle.load(open('resources/train_images_filenames.dat','rb'))\n",
    "test_images_filenames = cPickle.load(open('resources/test_images_filenames.dat','rb'))\n",
    "train_labels = cPickle.load(open('resources/train_labels.dat','rb'))\n",
    "test_labels = cPickle.load(open('resources/test_labels.dat','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIFTdetector = cv2.SIFT_create(nfeatures=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dense_sift(gray,sift,step):\n",
    "    step_size = step\n",
    "    kp = [cv2.KeyPoint(x, y, step_size) for y in range(0, gray.shape[0], step_size) \n",
    "                                        for x in range(0, gray.shape[1], step_size)]\n",
    "    dense_feat = sift.compute(gray, kp)\n",
    "    dense_feat_des = dense_feat[1]\n",
    "    return dense_feat_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step=5\n",
    "\n",
    "today = datetime.now()\n",
    "dt_string = today.strftime(\"%H:%M:%S\")\n",
    "print(f\"{dt_string} started doing step={step}\")\n",
    "\n",
    "Train_descriptors = []\n",
    "Train_label_per_descriptor = []\n",
    "\n",
    "for filename,labels in zip(train_images_filenames,train_labels):\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "#     kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "    des=compute_dense_sift(gray,SIFTdetector, step)\n",
    "    Train_descriptors.append(des)\n",
    "    Train_label_per_descriptor.append(labels)\n",
    "\n",
    "D=np.vstack(Train_descriptors)\n",
    "\n",
    "k=128\n",
    "codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "codebook.fit(D)\n",
    "\n",
    "visual_words=np.zeros((len(Train_descriptors),k),dtype=np.float32)\n",
    "for i in range(len(Train_descriptors)):\n",
    "    words=codebook.predict(Train_descriptors[i])\n",
    "    visual_words[i,:]=normalize(np.bincount(words,minlength=k).reshape(1,-1))\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=37,n_jobs=-1,metric='manhattan')\n",
    "# knn.fit(visual_words, train_labels)\n",
    "\n",
    "today = datetime.now()\n",
    "dt_string = today.strftime(\"%H:%M:%S\")\n",
    "print(f\"{dt_string} started doing step={step}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "ax.bar(range(0,len(visual_words[0])),visual_words[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(visual_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Kernel with scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_clf = svm.LinearSVC(max_iter=2000, C=10)\n",
    "lin_clf.fit(visual_words, train_labels)\n",
    "\n",
    "visual_words_test=np.zeros((len(test_images_filenames),k),dtype=np.float32)\n",
    "for i in range(len(test_images_filenames)):\n",
    "    filename=test_images_filenames[i]\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "#     kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "    des=compute_dense_sift(gray,SIFTdetector, step)\n",
    "    words=codebook.predict(des)\n",
    "    visual_words_test[i,:]=normalize(np.bincount(words,minlength=k).reshape(1,-1))\n",
    "\n",
    "visual_words_test=scaler.transform(visual_words_test)\n",
    "scores = cross_val_score(lin_clf, visual_words_test, test_labels, cv=5)\n",
    "accuracy=scores.mean()*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF Kernel with scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svc = svm.SVC(kernel='rbf', C=1000, gamma=0.001)\n",
    "rbf_svc.fit(visual_words, train_labels)\n",
    "\n",
    "visual_words_test=np.zeros((len(test_images_filenames),k),dtype=np.float32)\n",
    "for i in range(len(test_images_filenames)):\n",
    "    filename=test_images_filenames[i]\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "#     kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "    des=compute_dense_sift(gray,SIFTdetector, step)\n",
    "    words=codebook.predict(des)\n",
    "    visual_words_test[i,:]=normalize(np.bincount(words,minlength=k).reshape(1,-1))\n",
    "\n",
    "visual_words_test=scaler.transform(visual_words_test)\n",
    "scores = cross_val_score(rbf_svc, visual_words_test, test_labels, cv=5)\n",
    "\n",
    "accuracy=scores.mean()*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor filename,labels in zip(train_images_filenames,train_labels):\\n    ima=cv2.imread(filename)\\n    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\\n    break\\n\\ntiles = get_pyramid_image_cells(gray,2)\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pyramid_image_cells(image,level):\n",
    "    # CURRENTLY WORKING ONLY FOR LEVELS 0,1,2 (1,4, and 16 cells)\n",
    "    M = (image.shape[0])//(level+1)\n",
    "    N = (image.shape[1])//(level+1)\n",
    "    tiles = [image[x:x+M,y:y+N] for x in range(0,image.shape[0],M) for y in range(0,image.shape[1],N)]\n",
    "#     print(image.shape)\n",
    "#     print(\"level=\", level)\n",
    "#     print(\"returning \" + str(len(tiles)) + \" tiles\")\n",
    "    return tiles\n",
    "\n",
    "\n",
    "'''\n",
    "for filename,labels in zip(train_images_filenames,train_labels):\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    break\n",
    "\n",
    "tiles = get_pyramid_image_cells(gray,2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating a histogram per cell and concatenating them\n",
    "Compute a histogram for each part of the image and put these histograms together in a weighted concatenation \n",
    "(since there will be less words overall in a smaller cell).\n",
    "The weighted concatenation can be a simple normalization of every histogram so the area of the histogram adds up to 1.\n",
    "A pyramid of l levels will yield in 2^(2l) histograms n_words = k*(1+2**(2*pyramid_levels)).\n",
    "the final image histogram is a concatenated vector  of  the  bin  values  of  all  the  histograms in  the  pyramid.\n",
    "concatenation method used in:\n",
    "http://lear.imag.fr/pub/203-bosch-civr07.pdf\n",
    "https://core.ac.uk/download/pdf/82695491.pdf\n",
    "\n",
    "TODO: Initialisation of concatenated_histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:20:54 started doing step=5\n",
      "(256, 256)\n",
      "level= 0\n",
      "returning 1 tiles\n",
      "(256, 256)\n",
      "level= 1\n",
      "returning 4 tiles\n",
      "(256, 256)\n",
      "level= 2\n",
      "returning 16 tiles\n",
      "19:21:09 started doing step=5\n"
     ]
    }
   ],
   "source": [
    "step=5\n",
    "\n",
    "today = datetime.now()\n",
    "dt_string = today.strftime(\"%H:%M:%S\")\n",
    "print(f\"{dt_string} started doing step={step}\")\n",
    "\n",
    "Train_descriptors = []\n",
    "Train_label_per_descriptor = []\n",
    "pyramid_levels = 2 # level zero has 1 tile, level 1 has 4 tiles => 5 histograms that will be concatenated\n",
    "for filename,labels in zip(train_images_filenames,train_labels):\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    # break the image into pieces\n",
    "    image_cells = []\n",
    "    for i in range(pyramid_levels+1):\n",
    "\n",
    "        level_cells = get_pyramid_image_cells(gray,level=i)\n",
    "        image_cells = image_cells + level_cells\n",
    "        # compute descriptors for each tile\n",
    "    Train_descriptors_cell = []\n",
    "    for cell in image_cells:\n",
    "        des=compute_dense_sift(cell,SIFTdetector, step)\n",
    "        Train_descriptors_cell.append(des)\n",
    "    \n",
    "    Train_descriptors.append(Train_descriptors_cell)\n",
    "    Train_label_per_descriptor.append(labels)\n",
    "    break\n",
    "    \n",
    "today = datetime.now()\n",
    "dt_string = today.strftime(\"%H:%M:%S\")\n",
    "print(f\"{dt_string} started doing step={step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Train_descriptors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2704"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Train_descriptors[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Train_descriptors[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   2.,\n",
       "         0.,   0.,   0.,   0.,   2.,   2.,   4.,  26.,   4.,   0.,   0.,\n",
       "         0.,  26.,   5.,   3.,   5.,   0.,   0.,   0.,   8.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  57.,  31.,   1.,\n",
       "         0.,   0.,   0.,  96.,  82., 156., 156.,   8.,   0.,   0.,  17.,\n",
       "       156.,  41.,  24.,  19.,   0.,   0.,   0., 125.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  25.,  29.,   0.,   0.,\n",
       "        23.,   7., 156., 116., 124.,  76.,   0.,   0., 105., 156., 156.,\n",
       "        57.,   4.,   0.,   0.,   0.,   5., 156.], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_descriptors[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train all cells as separate images\n",
    "D=np.vstack([des for descriptors_cells in Train_descriptors for des in descriptors_cells])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=128\n",
    "codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "codebook.fit(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(k*(1+2**(2*pyramid_levels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Train_descriptors[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words=np.zeros((len(Train_descriptors),k*(1+2**(2*pyramid_levels))),dtype=np.float32)\n",
    "for idx,cells in enumerate(Train_descriptors):\n",
    "\n",
    "    image_histograms = []\n",
    "    for id2,image_cell in enumerate(cells):\n",
    "        cell_words = codebook.predict(image_cell)\n",
    "        image_histograms.append(normalize(np.bincount(cell_words,minlength=k).reshape(1,-1)))\n",
    "        # concatenated histogram has k*(1+2**(2*pyramid_levels)) bins\n",
    "        # normalize(np.bincount(words,minlength=k).reshape(1,-1))\n",
    "\n",
    "    concatenated_histogram=image_histograms[0].copy()\n",
    "    for cell_idx in range(1,len(image_histograms)):\n",
    "        # concatenate histograms\n",
    "        concatenated_histogram = np.concatenate((concatenated_histogram,image_histograms[cell_idx]))\n",
    "    visual_words[idx,:]=concatenated_histogram.flatten()\n",
    "    \n",
    "    #visual_words[idx,:]=np.bincount(words,minlength=k*(2**(2*pyramid_levels))) # this will just be longer as levels \n",
    "                                                                                # increase \n",
    "                                                                                # see: k*(2**(2*pyramid_levels)) long\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=37,n_jobs=-1,metric='manhattan')\n",
    "# knn.fit(visual_words, train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words[0,:].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINED Visual Words tryin further worked until now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(visual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_clf = svm.LinearSVC(max_iter=2000,C=10)\n",
    "lin_clf.fit(visual_words, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_svc = svm.SVC(kernel='rbf',C=1000,gamma=0.001)\n",
    "rbf_svc.fit(visual_words, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_svc = svm.SVC(kernel=intersection_kernel_cmp)\n",
    "inter_svc.fit(visual_words,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now()\n",
    "dt_string = today.strftime(\"%H:%M:%S\")\n",
    "print(f\"{dt_string} started doing step={step}\")\n",
    "\n",
    "Test_descriptors = []\n",
    "Test_label_per_descriptor = []\n",
    "pyramid_levels = 1 # level zero has 1 tile, level 1 has 4 tiles => 5 histograms that will be concatenated\n",
    "for filename,labels in zip(test_images_filenames,test_labels):\n",
    "    ima=cv2.imread(filename)\n",
    "    gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    # break the image into pieces\n",
    "    image_cells = []\n",
    "    for i in range(pyramid_levels+1):\n",
    "\n",
    "        level_cells = get_pyramid_image_cells(gray,level=i)\n",
    "        image_cells = image_cells + level_cells\n",
    "        # compute descriptors for each tile\n",
    "    Test_descriptors_cell = []\n",
    "    for cell in image_cells:\n",
    "        des=compute_dense_sift(cell,SIFTdetector, step)\n",
    "        Test_descriptors_cell.append(des)\n",
    "        \n",
    "    Test_descriptors.append(Test_descriptors_cell)\n",
    "    Test_label_per_descriptor.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words_test=np.zeros((len(Test_descriptors),k*(1+2**(2*pyramid_levels))),dtype=np.float32)\n",
    "for idx,cells in enumerate(Test_descriptors):\n",
    "\n",
    "    image_histograms = []\n",
    "    for id2,image_cell in enumerate(cells):\n",
    "        cell_words = codebook.predict(image_cell)\n",
    "        image_histograms.append(normalize(np.bincount(cell_words,minlength=k).reshape(1,-1)))\n",
    "        # concatenated histogram has k*(1+2**(2*pyramid_levels)) bins\n",
    "        # normalize(np.bincount(words,minlength=k).reshape(1,-1))\n",
    "\n",
    "    concatenated_histogram=image_histograms[0].copy()\n",
    "    for cell_idx in range(1,len(image_histograms)):\n",
    "        # concatenate histograms\n",
    "        concatenated_histogram = np.concatenate((concatenated_histogram,image_histograms[cell_idx]))\n",
    "    visual_words_test[idx,:]=concatenated_histogram.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_words_test=scaler.transform(visual_words_test)\n",
    "scores = cross_val_score(lin_clf, visual_words_test, test_labels, cv=5)\n",
    "accuracy=scores.mean()*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual_words_test=scaler.transform(visual_words_test)\n",
    "scores = cross_val_score(rbf_svc, visual_words_test, test_labels, cv=5)\n",
    "accuracy=scores.mean()*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating kernel for intersection of histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_kernel_cmp(X, Y):\n",
    "    return cv2.compareHist(X, Y, method=cv2.HISTCMP_INTERSECT)\n",
    "\n",
    "# clf = svm.SVC(kernel=my_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_kernel_cmp(visual_words[0],visual_words[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV cross validation finding best parameters for RBF and Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision_macro', 'recall_macro','accuracy']\n",
    "\n",
    "today = datetime.now()\n",
    "dt_string = today.strftime(\"%H:%M:%S\")\n",
    "print(f\"{dt_string} started doing step={step}\")\n",
    "\n",
    "data_results=[]\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring=score\n",
    "    )\n",
    "    clf.fit(visual_words, train_labels)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        c=params['C']\n",
    "        ker=params['kernel']\n",
    "        if ker=='rbf': \n",
    "            gamma=params['gamma']\n",
    "        else: gamma=None\n",
    "            \n",
    "        data_results.append([mean,std,c,gamma,ker,score])\n",
    "        \n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "#     print(\"Detailed classification report:\")\n",
    "#     print()\n",
    "#     print(\"The model is trained on the full development set.\")\n",
    "#     print(\"The scores are computed on the full evaluation set.\")\n",
    "#     print()\n",
    "#     y_true, y_pred = y_test, clf.predict(X_test)\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "#     print()\n",
    "\n",
    "today = datetime.now()\n",
    "dt_string = today.strftime(\"%H:%M:%S\")\n",
    "print(f\"{dt_string} started doing step={step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data_results, columns=['mean_val','std_val','c','gamma','ker','score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('GridSearchCV_rbf_linear_params.pkl','wb') as f:\n",
    "    cPickle.dump(df,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.set(title='Accuracy vs C', xlim=(0,1200), ylim=(0,1))\n",
    "df2=df[df.score=='accuracy']\n",
    "df2_rbf=df2[(df2.ker=='rbf')]\n",
    "df2_linear=df2[(df2.ker=='linear')]\n",
    "print(\"max for rbf\\n\",df2_rbf[df2_rbf.mean_val==df2_rbf.mean_val.max()])\n",
    "print(\"max for linear\\n\",df2_linear.loc[df2_linear.mean_val==df2_linear.mean_val.max()])\n",
    "# print(df2[df2.recall==df2.recall.max()])\n",
    "\n",
    "ax.plot(df2_linear.c, df2_linear.mean_val, 'ro', label='linear')\n",
    "ax.plot(df2_rbf.c, df2_rbf.mean_val, 'go', label='rbf')\n",
    "ax.legend()\n",
    "\n",
    "max_val = max(df2.mean_val)\n",
    "max_idx = df2.c[df2.mean_val.idxmax()]\n",
    "# ax.annotate(\"Max {:.2f}\".format(max_val), xy=(max_idx, max_val),\n",
    "#            weight='bold', size=14)\n",
    "\n",
    "# arrowprops is a mpl.patches.FancyArrowPatch\n",
    "_ = ax.annotate(\"Max accuracy {:.2f}\".format(max_val), xy=(max_idx, max_val),\n",
    "                weight='bold', size=14, \n",
    "                xytext=(.5, .9),\n",
    "                textcoords='axes fraction',\n",
    "                family='comic sans ms',\n",
    "                arrowprops={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Analysis for different DENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_kernel_cmp(X, Y):\n",
    "    kernel = np.zeros((X.shape[0], Y.shape[0]))\n",
    "\n",
    "    for d in range(X.shape[1]):\n",
    "        column_1 = X[:, d].reshape(-1, 1)\n",
    "        column_2 = Y[:, d].reshape(-1, 1)\n",
    "        kernel += np.minimum(column_1, column_2.T)\n",
    "\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vis(step):\n",
    "    step=step\n",
    "\n",
    "    today = datetime.now()\n",
    "    dt_string = today.strftime(\"%H:%M:%S\")\n",
    "    print(f\"{dt_string} started doing step={step}\")\n",
    "\n",
    "    Train_descriptors = []\n",
    "    Train_label_per_descriptor = []\n",
    "\n",
    "    for filename,labels in zip(train_images_filenames,train_labels):\n",
    "        ima=cv2.imread(filename)\n",
    "        gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    #     kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "        des=compute_dense_sift(gray,SIFTdetector, step)\n",
    "        Train_descriptors.append(des)\n",
    "        Train_label_per_descriptor.append(labels)\n",
    "\n",
    "    D=np.vstack(Train_descriptors)\n",
    "\n",
    "    k=128\n",
    "    codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "    codebook.fit(D)\n",
    "\n",
    "    visual_words=np.zeros((len(Train_descriptors),k),dtype=np.float32)\n",
    "    for i in range(len(Train_descriptors)):\n",
    "        words=codebook.predict(Train_descriptors[i])\n",
    "        visual_words[i,:]=normalize(np.bincount(words,minlength=k).reshape(1,-1))\n",
    "\n",
    "    # knn = KNeighborsClassifier(n_neighbors=37,n_jobs=-1,metric='manhattan')\n",
    "    # knn.fit(visual_words, train_labels)\n",
    "\n",
    "    today = datetime.now()\n",
    "    dt_string = today.strftime(\"%H:%M:%S\")\n",
    "    print(f\"{dt_string} started doing step={step}\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit_transform(visual_words)\n",
    "    \n",
    "#     lin_clf = svm.LinearSVC(max_iter=2000, C=10)\n",
    "#     lin_clf.fit(visual_words, train_labels)\n",
    "    \n",
    "#     rbf_svc = svm.SVC(kernel='rbf', C=1000, gamma=0.001)\n",
    "#     rbf_svc.fit(visual_words, train_labels)\n",
    "    \n",
    "    intersection_clf = svm.SVC(kernel=intersection_kernel_cmp)\n",
    "    intersection_clf.fit(visual_words, train_labels)\n",
    "\n",
    "    visual_words_test=np.zeros((len(test_images_filenames),k),dtype=np.float32)\n",
    "    for i in range(len(test_images_filenames)):\n",
    "        filename=test_images_filenames[i]\n",
    "        ima=cv2.imread(filename)\n",
    "        gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "    #     kpt,des=SIFTdetector.detectAndCompute(gray,None)\n",
    "        des=compute_dense_sift(gray,SIFTdetector, step)\n",
    "        words=codebook.predict(des)\n",
    "        visual_words_test[i,:]=normalize(np.bincount(words,minlength=k).reshape(1,-1))\n",
    "\n",
    "    visual_words_test=scaler.transform(visual_words_test)\n",
    "    \n",
    "#     scores = cross_val_score(lin_clf, visual_words_test, test_labels, cv=5)\n",
    "#     accuracy_linear=scores.mean()*100\n",
    "\n",
    "#     print(\"linear=\",accuracy_linear)\n",
    "\n",
    "#     scores = cross_val_score(rbf_svc, visual_words_test, test_labels, cv=5)\n",
    "#     accuracy_rbf=scores.mean()*100\n",
    "\n",
    "#     print(\"rbf=\",accuracy_rbf)\n",
    "    \n",
    "    scores = cross_val_score(intersection_clf, visual_words_test, test_labels, cv=5)\n",
    "    accuracy_inter=scores.mean()*100\n",
    "\n",
    "    print(\"inter=\",accuracy_inter)\n",
    "    \n",
    "    return accuracy_inter\n",
    "#     return accuracy_linear,accuracy_rbf,accuracy_inter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:41:27 started doing step=5\n",
      "14:44:04 started doing step=5\n",
      "inter= 80.17560003067251\n",
      "14:45:11 started doing step=20\n",
      "14:47:05 started doing step=20\n",
      "inter= 77.56767119085958\n",
      "14:47:59 started doing step=50\n",
      "14:49:26 started doing step=50\n",
      "inter= 65.0502262096465\n",
      "14:50:11 started doing step=100\n",
      "14:50:59 started doing step=100\n",
      "inter= 61.58116708841346\n",
      "14:51:29 started doing step=300\n",
      "14:51:48 started doing step=300\n",
      "inter= 56.25718886588451\n",
      "14:52:03 started doing step=500\n",
      "14:52:19 started doing step=500\n",
      "inter= 56.12989801395598\n"
     ]
    }
   ],
   "source": [
    "data_results_step =[]\n",
    "steps_to_do=[5,20,50,100,300,500]\n",
    "for step in steps_to_do:\n",
    "#     accuracy_linear,accuracy_rbf=calculate_vis(step)\n",
    "    accuracy_inter=calculate_vis(step)\n",
    "    data_results_step.append([step,accuracy_inter,1,1])\n",
    "    \n",
    "df=pd.DataFrame(data_results_step, columns=['step','accuracy_inter','normalized','scaler'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>accuracy_inter</th>\n",
       "      <th>normalized</th>\n",
       "      <th>scaler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>80.175600</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>77.567671</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>65.050226</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>61.581167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>56.257189</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>56.129898</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step  accuracy_inter  normalized  scaler\n",
       "0     5       80.175600           1       1\n",
       "1    20       77.567671           1       1\n",
       "2    50       65.050226           1       1\n",
       "3   100       61.581167           1       1\n",
       "4   300       56.257189           1       1\n",
       "5   500       56.129898           1       1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>accuracy_linear</th>\n",
       "      <th>accuracy_rbf</th>\n",
       "      <th>normalized</th>\n",
       "      <th>scaler</th>\n",
       "      <th>accuracy_inter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>65.548654</td>\n",
       "      <td>78.937198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>80.175600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>63.446055</td>\n",
       "      <td>72.614063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77.567671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>52.413159</td>\n",
       "      <td>62.947627</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65.050226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>53.275056</td>\n",
       "      <td>59.352810</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61.581167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>54.897631</td>\n",
       "      <td>57.619048</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56.257189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>53.771950</td>\n",
       "      <td>57.119086</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56.129898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step  accuracy_linear  accuracy_rbf  normalized  scaler  accuracy_inter\n",
       "0     5        65.548654     78.937198           1       1       80.175600\n",
       "1    20        63.446055     72.614063           1       1       77.567671\n",
       "2    50        52.413159     62.947627           1       1       65.050226\n",
       "3   100        53.275056     59.352810           1       1       61.581167\n",
       "4   300        54.897631     57.619048           1       1       56.257189\n",
       "5   500        53.771950     57.119086           1       1       56.129898"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Different_densities_analysis.pkl','wb') as f:\n",
    "    cPickle.dump(df_all,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max for rbf\n",
      "    step  accuracy_linear  accuracy_rbf  normalized  scaler\n",
      "0     5        65.548654     78.937198           1       1\n",
      "max for linear\n",
      "    step  accuracy_linear  accuracy_rbf  normalized  scaler\n",
      "0     5        65.548654     78.937198           1       1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d206583220>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.set(title='Accuracy vs steps', xlim=(0,1200), ylim=(0,100))\n",
    "df2=df\n",
    "y_rbf=df2.accuracy_rbf\n",
    "y_lin=df2.accuracy_linear\n",
    "print(\"max for rbf\\n\",df2[df2.accuracy_rbf==df2.accuracy_rbf.max()])\n",
    "print(\"max for linear\\n\",df2[df2.accuracy_linear==df2.accuracy_linear.max()])\n",
    "# print(df2[df2.recall==df2.recall.max()])\n",
    "\n",
    "ax.plot(df2.step, y_lin, 'r', label='linear')\n",
    "ax.plot(df2.step, y_rbf, 'g', label='rbf')\n",
    "plt.xlabel('step in dense')\n",
    "plt.ylabel('accuracy')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>accuracy_linear</th>\n",
       "      <th>accuracy_rbf</th>\n",
       "      <th>normalized</th>\n",
       "      <th>scaler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>65.548654</td>\n",
       "      <td>78.937198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>63.446055</td>\n",
       "      <td>72.614063</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>52.413159</td>\n",
       "      <td>62.947627</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>53.275056</td>\n",
       "      <td>59.352810</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>54.897631</td>\n",
       "      <td>57.619048</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>53.771950</td>\n",
       "      <td>57.119086</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step  accuracy_linear  accuracy_rbf  normalized  scaler\n",
       "0     5        65.548654     78.937198           1       1\n",
       "1    20        63.446055     72.614063           1       1\n",
       "2    50        52.413159     62.947627           1       1\n",
       "3   100        53.275056     59.352810           1       1\n",
       "4   300        54.897631     57.619048           1       1\n",
       "5   500        53.771950     57.119086           1       1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Different_densities_analysis.pkl','wb') as f:\n",
    "    cPickle.dump(df,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Analysis on Pyramid level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pyramid_levels(pyramid):\n",
    "    step=5\n",
    "\n",
    "    today = datetime.now()\n",
    "    dt_string = today.strftime(\"%H:%M:%S\")\n",
    "    print(f\"{dt_string} started doing step={pyramid}\")\n",
    "\n",
    "    Train_descriptors = []\n",
    "    Train_label_per_descriptor = []\n",
    "    pyramid_levels = pyramid # level zero has 1 tile, level 1 has 4 tiles => 5 histograms that will be concatenated\n",
    "\n",
    "    for filename,labels in zip(train_images_filenames,train_labels):\n",
    "        ima=cv2.imread(filename)\n",
    "        gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "        # break the image into pieces\n",
    "        image_cells = []\n",
    "        for i in range(pyramid_levels+1):\n",
    "\n",
    "            level_cells = get_pyramid_image_cells(gray,level=i)\n",
    "            image_cells = image_cells + level_cells\n",
    "            # compute descriptors for each tile\n",
    "        Train_descriptors_cell = []\n",
    "        for cell in image_cells:\n",
    "            des=compute_dense_sift(cell,SIFTdetector, step)\n",
    "            Train_descriptors_cell.append(des)\n",
    "\n",
    "        Train_descriptors.append(Train_descriptors_cell)\n",
    "        Train_label_per_descriptor.append(labels)\n",
    "\n",
    "    D=np.vstack([des for descriptors_cells in Train_descriptors for des in descriptors_cells])\n",
    "\n",
    "    #codebook\n",
    "\n",
    "    k=128\n",
    "    codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "    codebook.fit(D)\n",
    "\n",
    "    #creating visual words for Training\n",
    "\n",
    "    visual_words=np.zeros((len(Train_descriptors),k*21),dtype=np.float32)\n",
    "    for idx,cells in enumerate(Train_descriptors):\n",
    "\n",
    "        image_histograms = []\n",
    "        for id2,image_cell in enumerate(cells):\n",
    "            cell_words = codebook.predict(image_cell)\n",
    "            image_histograms.append(normalize(np.bincount(cell_words,minlength=k).reshape(1,-1)))\n",
    "            # concatenated histogram has k*(1+2**(2*pyramid_levels)) bins\n",
    "            # normalize(np.bincount(words,minlength=k).reshape(1,-1))\n",
    "\n",
    "        concatenated_histogram=image_histograms[0].copy()\n",
    "        for cell_idx in range(1,len(image_histograms)):\n",
    "            # concatenate histograms\n",
    "            concatenated_histogram = np.concatenate((concatenated_histogram,image_histograms[cell_idx]))\n",
    "        visual_words[idx,:]=concatenated_histogram.flatten()\n",
    "        \n",
    "    #PCA\n",
    "    pca = PCA(n_components=0.95)\n",
    "    VWpca = pca.fit_transform(visual_words)\n",
    "    \n",
    "    #LDA\n",
    "#     lda = LinearDiscriminantAnalysis(n_components=7)\n",
    "#     VWlda = lda.fit_transform(visual_words,train_labels)\n",
    "\n",
    "    #SVN kernels\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit_transform(VWpca)\n",
    "\n",
    "    lin_clf = svm.LinearSVC(max_iter=2000, C=10)\n",
    "    lin_clf.fit(VWpca, train_labels)\n",
    "\n",
    "    rbf_svc = svm.SVC(kernel='rbf', C=1000, gamma=0.001)\n",
    "    rbf_svc.fit(VWpca, train_labels)\n",
    "    \n",
    "    intersection_clf = svm.SVC(kernel=intersection_kernel_cmp)\n",
    "    intersection_clf.fit(VWpca, train_labels)\n",
    "\n",
    "    today = datetime.now()\n",
    "    dt_string = today.strftime(\"%H:%M:%S\")\n",
    "    print(f\"{dt_string} started doing test step={pyramid}\")\n",
    "\n",
    "    #creating SIFT descriptor\n",
    "\n",
    "    Test_descriptors = []\n",
    "    Test_label_per_descriptor = []\n",
    "    # pyramid_levels = 1 # level zero has 1 tile, level 1 has 4 tiles => 5 histograms that will be concatenated\n",
    "    for filename,labels in zip(test_images_filenames,test_labels):\n",
    "        ima=cv2.imread(filename)\n",
    "        gray=cv2.cvtColor(ima,cv2.COLOR_BGR2GRAY)\n",
    "        # break the image into pieces\n",
    "        image_cells = []\n",
    "        for i in range(pyramid_levels+1):\n",
    "\n",
    "            level_cells = get_pyramid_image_cells(gray,level=i)\n",
    "            image_cells = image_cells + level_cells\n",
    "            # compute descriptors for each tile\n",
    "        Test_descriptors_cell = []\n",
    "        for cell in image_cells:\n",
    "            des=compute_dense_sift(cell,SIFTdetector, step)\n",
    "            Test_descriptors_cell.append(des)\n",
    "\n",
    "        Test_descriptors.append(Test_descriptors_cell)\n",
    "        Test_label_per_descriptor.append(labels)\n",
    "\n",
    "    #creating visual tests\n",
    "\n",
    "    visual_words_test=np.zeros((len(Test_descriptors),k*21),dtype=np.float32)\n",
    "    for idx,cells in enumerate(Test_descriptors):\n",
    "\n",
    "        image_histograms = []\n",
    "        for id2,image_cell in enumerate(cells):\n",
    "            cell_words = codebook.predict(image_cell)\n",
    "            image_histograms.append(normalize(np.bincount(cell_words,minlength=k).reshape(1,-1)))\n",
    "            # concatenated histogram has k*(1+2**(2*pyramid_levels)) bins\n",
    "            # normalize(np.bincount(words,minlength=k).reshape(1,-1))\n",
    "\n",
    "        concatenated_histogram=image_histograms[0].copy()\n",
    "        for cell_idx in range(1,len(image_histograms)):\n",
    "            # concatenate histograms\n",
    "            concatenated_histogram = np.concatenate((concatenated_histogram,image_histograms[cell_idx]))\n",
    "        visual_words_test[idx,:]=concatenated_histogram.flatten()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #PCA\n",
    "    vwtestpca = pca.transform(visual_words_test)\n",
    "    \n",
    "    #LDA\n",
    "#     vwtestlda = lda.transform(visual_words_test)\n",
    "    \n",
    "    #scaler test\n",
    "    visual_words_test=scaler.transform(vwtestpca)\n",
    "    \n",
    "\n",
    "    #accuracy for test linear\n",
    "    scores = cross_val_score(lin_clf, visual_words_test, test_labels, cv=5)\n",
    "    accuracy_linear=scores.mean()*100\n",
    "\n",
    "    print(\"linear=\",accuracy_linear)\n",
    "\n",
    "\n",
    "    #accuracy for test rbf\n",
    "    scores = cross_val_score(rbf_svc, visual_words_test, test_labels, cv=5)\n",
    "    accuracy_rbf=scores.mean()*100\n",
    "\n",
    "    print(\"rbf=\",accuracy_rbf)\n",
    "    \n",
    "    #accuracy for test inter\n",
    "    scores = cross_val_score(intersection_clf, visual_words_test, test_labels, cv=5)\n",
    "    accuracy_inter=scores.mean()*100\n",
    "\n",
    "    print(\"inter=\",accuracy_inter)\n",
    "    \n",
    "    return accuracy_linear,accuracy_rbf,accuracy_inter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_level=pd.DataFrame(data_pyramid_levels, columns=['level','step','accuracy_linear','accuracy_rbf','accuracy_inter','normalized','scaler','lda']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:25:21 started doing step=2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-eb4d65352f00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata_pyramid_levels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpiramid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0maccuracy_linear\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_rbf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_inter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_pyramid_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mdata_pyramid_levels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_linear\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_rbf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_inter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.95\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-55-c63973a869a8>\u001b[0m in \u001b[0;36mcreate_pyramid_levels\u001b[1;34m(pyramid)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mTrain_descriptors_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimage_cells\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mdes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_dense_sift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSIFTdetector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mTrain_descriptors_cell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-d2310b441c0e>\u001b[0m in \u001b[0;36mcompute_dense_sift\u001b[1;34m(gray, sift, step)\u001b[0m\n\u001b[0;32m      3\u001b[0m     kp = [cv2.KeyPoint(x, y, step_size) for y in range(0, gray.shape[0], step_size) \n\u001b[0;32m      4\u001b[0m                                         for x in range(0, gray.shape[1], step_size)]\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdense_feat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdense_feat_des\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdense_feat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdense_feat_des\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "piramid=[2]\n",
    "data_pyramid_levels=[]\n",
    "for level in piramid:\n",
    "    accuracy_linear,accuracy_rbf, accuracy_inter=create_pyramid_levels(level)\n",
    "    data_pyramid_levels.append([level,5,accuracy_linear,accuracy_rbf, accuracy_inter,1,1,0.95])\n",
    "\n",
    "df_level=pd.DataFrame(data_pyramid_levels, columns=['level','step','accuracy_linear','accuracy_rbf','accuracy_inter','normalized','scaler','pca'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:31:36 started doing step=1\n",
      "15:35:18 started doing test step=1\n",
      "inter= 72.73982056590754\n"
     ]
    }
   ],
   "source": [
    "piramid=[2]\n",
    "data_pyramid_levels=[]\n",
    "for level in piramid:\n",
    "    accuracy_inter=create_pyramid_levels(level)\n",
    "    data_pyramid_levels.append([level,5,accuracy_inter,1,1])\n",
    "\n",
    "df_level=pd.DataFrame(data_pyramid_levels, columns=['level','step','accuracy_inter','normalized','scaler'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_level['pca']=127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Different_pyramid_level_2_all_pca_0_95.pkl','wb') as f:\n",
    "    cPickle.dump(df_level,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
